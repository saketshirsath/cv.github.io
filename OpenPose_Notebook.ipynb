{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the model to be used\n",
    "COCO and MPI are body pose estimation model. COCO has 18 points and MPI has 15 points as output.\n",
    "\n",
    "HAND is hand keypoints estimation model. It has 22 points as output\n",
    "\n",
    "Ensure that the model files are available in the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"MPI\"\n",
    "\n",
    "if MODE is \"COCO\":\n",
    "    protoFile = \"pose/coco/pose_deploy_linevec.prototxt\"\n",
    "    weightsFile = \"pose/coco/pose_iter_440000.caffemodel\"\n",
    "    nPoints = 18\n",
    "    POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "elif MODE is \"MPI\" :\n",
    "    protoFile = \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "    weightsFile = \"pose/mpi/pose_iter_160000.caffemodel\"\n",
    "    nPoints = 15\n",
    "    POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-p_s0bnou/opencv/modules/dnn/src/caffe/caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\" in function 'ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dceca213638f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotoFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightsFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minWidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m368\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m368\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m inpBlob = cv2.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight),\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-p_s0bnou/opencv/modules/dnn/src/caffe/caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\" in function 'ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "inWidth = 368\n",
    "inHeight = 368\n",
    "inpBlob = cv2.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight),\n",
    "                          (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "net.setInput(inpBlob)\n",
    "output = net.forward()\n",
    "H = output.shape[2]\n",
    "W = output.shape[3]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the network and pass the image through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"exercises/bench/2.jpg\")\n",
    "frameCopy = np.copy(frame)\n",
    "frameBlack = np.zeros(frame.shape)\n",
    "frameWidth = frame.shape[1]\n",
    "frameHeight = frame.shape[0]\n",
    "threshold = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass it through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inWidth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e3b64f3a142d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n\u001b[0m\u001b[1;32m      2\u001b[0m                           (0, 0, 0), swapRB=False, crop=False)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpBlob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inWidth' is not defined"
     ]
    }
   ],
   "source": [
    "inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
    "                          (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "net.setInput(inpBlob)\n",
    "\n",
    "output = net.forward()\n",
    "H = output.shape[2]\n",
    "W = output.shape[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gather the points and plot the keypoints and the skeleton figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b729daa2d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnPoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# confidence map of corresponding body's part.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprobMap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Find global maxima of the probMap.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "# Empty list to store the detected keypoints\n",
    "points = []\n",
    "\n",
    "for i in range(nPoints):\n",
    "    # confidence map of corresponding body's part.\n",
    "    probMap = output[0, i, :, :]\n",
    "\n",
    "    # Find global maxima of the probMap.\n",
    "    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "    \n",
    "    # Scale the point to fit on the original image\n",
    "    x = (frameWidth * point[0]) / W\n",
    "    y = (frameHeight * point[1]) / H\n",
    "\n",
    "    if prob > threshold : \n",
    "        cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "        cv2.circle(frameBlack, (int(x), int(y)), 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.circle(frame, (int(x), int(y)), 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "        # Add the point to the list if the probability is greater than the threshold\n",
    "        points.append((int(x), int(y)))\n",
    "    else :\n",
    "        points.append(None)\n",
    "\n",
    "# Draw Skeleton\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]\n",
    "    partB = pair[1]\n",
    "\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(frameBlack, points[partA], points[partB], (0, 255, 255), 3)\n",
    "        cv2.line(frame, points[partA], points[partB], (0, 255, 255), 3)\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB))\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "#plt.imshow(frameBlack.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
